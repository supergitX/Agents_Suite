# ğŸ§¾ Project Overview

This project demonstrates an automated code generation, review, optimization, and testing workflow using Gemini and Groq large language models (LLMs) within a GitHub Actions environment. A user provides a prompt in `input.txt`, which is used to generate Python code. This generated code (`buggy_code.py`) is then automatically reviewed, and the review is used to create an optimized version (`reviewed_code.py`). Finally, tests are generated and run against the reviewed code. The entire process is managed through GitHub Actions workflows. The project also includes a documentation generation component using Gemini.

# âš™ï¸ Setup & Installation Instructions

1. **Clone the repository:**
   ```bash
   git clone <repository_url>
   ```

2. **Set up a virtual environment:**
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate  # On Linux/macOS
   .venv\Scripts\activate  # On Windows
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up environment variables:**
   Create a `.env` file in the root directory and add the following, replacing placeholders with your actual API keys:

   ```
   GEMINI_API_KEY=<your_gemini_api_key>
   GROQ_API_KEY=<your_groq_api_key>
   ```

# ğŸ§© Explanation of Key Modules, Classes, and Functions

## Python Files

- **`agents/code_generator.py`**: Generates Python code based on a prompt from `input.txt` using Gemini.
- **`agents/reviewer.py`**: Reviews code using the Groq API and saves the review to a file.
- **`agents/optimizer.py`**: Uses the Groq API to provide an optimized version of the code based on the review.
- **`agents/tester.py`**: Generates and runs pytest test cases against the optimized code using the Groq API.
- **`doc-keeper.py`**: Generates documentation for the repository using Gemini.
- **`reviewed_code.py`**: The final, reviewed and optimized version of the generated code. (Generated file)
- **`buggy_code.py`**: The initially generated code from the prompt, intended for review. (Generated file)
- **`generated_code/generated.py`**: The initially generated code from `input.txt`. (Generated file)
- **`output/fixed_code.py`**: The reviewed and fixed code by the optimizer agent. (Generated file)
- **`output/review.txt`**: The review generated by the optimizer agent. (Generated file)
- **`test_reviewed_code.py`**: The test cases generated for the reviewed code (Generated file)



## GitHub Actions Workflows

- **`.github/workflows/generate-code.yml`**: Triggers on changes to `input.txt` and runs `agents/code_generator.py`.
- **`.github/workflows/code-review.yml`**: Triggers after code generation and runs `agents/reviewer.py`.
- **`.github/workflows/optimize.yml`**: Triggers after code review and runs `agents/optimizer.py`.
- **`.github/workflows/run-tests.yml`**: Triggers after optimization and runs `agents/tester.py`.
- **`.github/workflows/dockeeper.yml`**: Triggers on pushes to the main branch and runs `doc-keeper.py` to update the documentation.

# ğŸ—‚ Folder & File Structure with Descriptions

```
.
â”œâ”€â”€ .github
â”‚   â””â”€â”€ workflows
â”‚       â”œâ”€â”€ code-review.yml          # Workflow for code review
â”‚       â”œâ”€â”€ dockeeper.yml            # Workflow for documentation generation
â”‚       â”œâ”€â”€ generate-code.yml       # Workflow for code generation
â”‚       â”œâ”€â”€ optimize.yml            # Workflow for code optimization
â”‚       â””â”€â”€ run-tests.yml           # Workflow for running tests
â”œâ”€â”€ agents                      # Contains the agent scripts
â”‚   â”œâ”€â”€ code_generator.py        # Generates code from a prompt
â”‚   â”œâ”€â”€ optimizer.py            # Optimizes the code based on review
â”‚   â”œâ”€â”€ reviewer.py            # Reviews the generated code
â”‚   â””â”€â”€ tester.py              # Generates and runs tests
â”œâ”€â”€ generated_code             # Stores the initially generated code
â”‚   â””â”€â”€ generated.py
â”œâ”€â”€ output                     # Stores the reviewed and fixed code, and review comments
â”‚   â”œâ”€â”€ fixed_code.py
â”‚   â””â”€â”€ review.txt
â”œâ”€â”€ DOCUMENTATION.md          # Project documentation (this file)
â”œâ”€â”€ README.md                 # Project overview
â”œâ”€â”€ buggy_code.py             # Initially generated code (before review)
â”œâ”€â”€ doc-keeper.py             # Documentation generation script
â”œâ”€â”€ input.txt                 # Input prompt for code generation
â”œâ”€â”€ requirements.txt          # Project dependencies
â”œâ”€â”€ reviewed_code.py          # Reviewed and optimized code
â””â”€â”€ test_reviewed_code.py     # Generated test cases
```


# ğŸ”§ How to Use

This project is designed to be automated through GitHub Actions.  The primary way to interact with it is by modifying the `input.txt` file.  

1. **Update `input.txt`:**  Change the prompt in this file to describe the Python code you want to generate.
2. **Commit and Push:** Committing and pushing the changes to `input.txt` will trigger the GitHub Actions workflow.
3. **Observe the workflow:** Monitor the progress of the workflows in the "Actions" tab of your GitHub repository.  You can see the logs for each stage (code generation, review, optimization, testing).
4. **View Results:** The generated code, reviews, optimized code, and test results will be stored in the appropriate files and directories as described in the folder structure.

# ğŸ¤ Contribution Guidelines

Contributions are welcome! If you'd like to contribute to this project, please fork the repository and submit a pull request. Ensure your code adheres to PEP 8 style guidelines and includes appropriate docstrings.

# ğŸ§ª Testing & Debugging Instructions

The `test_reviewed_code.py` file contains automatically generated test cases for the `reviewed_code.py` file. You can run these tests locally using `pytest`:

```bash
pytest test_reviewed_code.py -v 
```

The `-v` flag provides verbose output. Use the `--tb=long` flag for detailed tracebacks if tests fail.  A log file `test_generation.log` is generated by the testing workflow and contains the test generation and pytest output.

Review the GitHub Actions workflow logs for insights into each stage of the automated process.

---



```python
import os
import datetime
import re
from pathlib import Path
import google.generativeai as genai

# ğŸ”‘ Load your Gemini API key (recommended to use environment variable)
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# â›” Files and folders to skip during documentation generation
IGNORE_EXTENSIONS = ('.pyc', '.log', '.lock', '.env', '.sqlite3', '.db')
IGNORE_FILES = ('requirements.lock', '.env', 'secrets.json')
IGNORE_DIRS = ('.git', '__pycache__', 'venv', 'node_modules', 'dist', 'build', '.idea', '.vscode', '.pytest_cache')

def read_repo_files(base_path: str) -> dict:
    """
    Recursively reads all readable files in the repository directory, excluding
    ignored directories and extensions.

    Parameters:
        base_path (str): The root directory of the repository.

    Returns:
        dict: A dictionary mapping relative file paths to their content.
    """
    file_data = {}

    for root, dirs, files in os.walk(base_path):
        dirs[:] = [d for d in dirs if d not in IGNORE_DIRS]

        for file in files:
            if file.endswith(IGNORE_EXTENSIONS) or file in IGNORE_FILES:
                continue

            file_path = os.path.join(root, file)
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                relative_path = os.path.relpath(file_path, base_path)
                file_data[relative_path] = content
            except Exception as e:
                print(f"âš ï¸ Skipping {file_path}: {e}")
    
    return file_data

def generate_documentation(repo_files: dict) -> str:
    """
    Generates Markdown documentation using Gemini based on the provided codebase.

    Parameters:
        repo_files (dict): A mapping of file paths to file content.

    Returns:
        str: Generated documentation in Markdown format.
    """
    prompt = """("You are an expert software architect and technical writer.\n"
        "Given the following codebase, generate a **complete and detailed** documentation in Markdown format. Be exhaustive and helpful for developers.\n\n"
        "Include the following sections:\n"
        "- ğŸ§¾ Project Overview\n"
        "- âš™ï¸ Setup & Installation Instructions\n"
        - "- ğŸ§© Explanation of Key Modules, Classes, and Functions\n"
        "- ğŸ—‚ Folder & File Structure with Descriptions\n"
        "- ğŸ”§ How to Use (with CLI or API examples if present)\n"
        "- ğŸ¤ Contribution Guidelines (if applicable)\n"
        "- ğŸ§ª Testing & Debugging Instructions (if test files exist)\n"
        "- ğŸ§  Add Python-style **docstrings** to all functions with descriptions of parameters and return types\n\n"
        "### Codebase Contents:\n")"""

    for filename, content in repo_files.items():
        trimmed_content = content[:3000]  # prevent token overflow
        prompt += f"\n#### FILE: {filename}\n```python\n{trimmed_content}\n```\n"

    model = genai.GenerativeModel('gemini-1.5-pro')
    response = model.generate_content(prompt)
    return response.text

def write_documentation(doc_text: str, output_file="DOCUMENTATION.md"):
    """Writes the generated documentation to a Markdown file."""
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(doc_text)
    print(f"âœ… Documentation generated and saved to {output_file}")

if __name__ == "__main__":
    repo_files = read_repo_files(".")
    documentation = generate_documentation(repo_files)
    write_documentation(documentation)

```

```python
def sum_of_even_numbers(numbers: list[int]) -> int:
    """
    Calculates the sum of all even numbers in a list of integers.

    Args:
      numbers: A list of integers.

    Returns:
      The sum of all even numbers in the list.

    Raises:
      TypeError: If the input is not a list or if the list contains non-integer values.
    """
    if not isinstance(numbers, list):
        raise TypeError("Input must be a list.")

    sum_even = 0
    for number in numbers:
        if not isinstance(number, int):
            raise TypeError("All elements in the list must be integers.")
        if number % 2 == 0:
            sum_even += number
    return sum_even
```

```python
def sum_of_even_numbers(numbers):
  """
  Calculates the sum of all even numbers in a list of integers.

  Args:
    numbers: A list of integers.

  Returns:
    The sum of all even numbers in the list.
  """
  sum_even = 0
  for number in numbers:
    if number % 2 == 0:
      sum_even += number
  return sum_even
```

```python

# Agents_Suite_Demo

a demosntration of how the agents can be linked together.

```


```python
name: Code Optimizer

on:
  workflow_run:
    workflows: ["Code Review"]  # <-- Name of your reviewer workflow YAML
    types:
      - completed
  workflow_dispatch:

permissions:
  contents: write

jobs:
  review-and-debug:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python environment
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'  # You can use another version if needed

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt  # Install from requirements.txt
          
      - name: Ensure output directory exists
        run: mkdir -p output
        
      - name: Run the code review and fix
        run: |
          python agents/optimizer.py  
        env:
            GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}

      - name: Commit fixed code and review to debug branch
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@users.noreply.github.com"

          git add output/ output/fixed_code.py output/review.txt  reviewed_code.py # Add the new files
          git commit -m "Review and debugged code" || echo "No changes to commit"
          git push origin main --force

```

```python
name: Code Review 

on:
  push:
    paths:
      - buggy_code.py
  workflow_run:
    workflows: ["Code Generator on Prompt Input"]  # <-- Name of your reviewer workflow YAML
    types:
      - completed
  workflow_dispatch:
  
permissions:
  contents: write  # Allows pushing changes to the repo

jobs:
  review:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests

    - name: Run Code Review on buggy_code.py
      env:
        GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
      run: |
        python agents/reviewer.py --file buggy_code.py

    - name: Upload Review Output
      if: success()
      uses: actions/upload-artifact@v4
      with:
        name: review-output
        path: reviews/

    - name: Commit and Push Review & Logs
      if: success()
      run: |
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        
        git add reviews/ logs/
        git commit -m "Add code review and logs for buggy_code.py" || echo "No changes to commit"
        git push origin main --force


```

```python
name: Generate Repository Documentation

on:
  # Automatically trigger on any push to any branch
  push:
    branches:
      - main  # All branches
  # Allow manual trigger from GitHub Actions tab
  workflow_dispatch:

permissions:
  contents: write  # Allows pushing changes to the repo

jobs:
  generate-docs:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          persist-credentials: true

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install required packages
        run: pip install google-generativeai

      - name: Run doc-keeper to generate documentation
        run: python doc-keeper.py
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}

      - name: Commit and push generated documentation
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions@github.com"
          git add DOCUMENTATION.md
          git commit -m "ğŸ“ Auto-generated documentation using doc-keeper" || echo "No changes to commit"

          git pull --rebase --strategy-option=theirs origin $(git rev-parse --abbrev-ref HEAD) || echo "Merge issue ignored"
          git push origin $(git rev-parse --abbrev-ref HEAD) --force

```

```python
name: Code Generator on Prompt Input

on:
  push:
    branches:
      - main
    paths:
      - 'input.txt'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  generate-code:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install google-generativeai

      - name: Run code generator
        run: python agents/code_generator.py
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}

      - name: Commit generated code
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@users.noreply.github.com"

          git add generated_code/generated.py buggy_code.py
          git commit -m "ğŸ¤– Auto-generated code from input.txt" || echo "No changes to commit"
          git push

```


```python
name: Run Tests on Reviewed Code

#on:
 # push:
  #  branches:
  #    - main  # Adjust the branch as needed
  #  paths:
 #     - reviewed_code.py 
 #workflow_dispatch:
on:
  workflow_run:
    workflows: ["Code Optimizer"]  # <-- Name of your reviewer workflow YAML
    types:
      - completed
  workflow_dispatch:
permissions:
  contents: write

jobs:
  run-tests:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          persist-credentials: true

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Generate and run test cases on fixed code
        run: |
          echo "======= ğŸš€ Test Run - $(date) =======" >> test_generation.log
          echo "===== ğŸ§ª Running Python Test Case Generation =====" >> test_generation.log
          python agents/tester.py >> test_generation.log 2>&1

          echo "===== ğŸ§ª Pytest Output =====" >> test_generation.log
          pytest test_reviewed_code.py -v --tb=long | tee -a test_generation.log || true
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}

      - name: Switch to test branch and commit generated files
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions@github.com"

          git checkout -B test

          git add test_reviewed_code.py test_generation.log reviewed_code.py
          git commit -m "ğŸ§ª Auto: generated tests + detailed log from master" || echo "No changes to commit"
          git push origin test --force

```

```python
import os
import datetime
import re
from pathlib import Path
import google.generativeai as genai

# Directory where the generated code will be saved
OUTPUT_DIR = Path("generated_code")
OUTPUT_DIR.mkdir(exist_ok=True)

# Gemini API setup: API key provided via GitHub Secrets as environment variable 'GEMINI_API_KEY'
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    raise EnvironmentError("GEMINI_API_KEY environment variable not set.")
genai.configure(api_key=api_key)

def read_prompt_from_file(file_path="input.txt") -> str:
    """Reads the plain-text prompt from a .txt file."""
    if not os.path.exists(file_path):
        print("âš ï¸ input.txt not found. Using fallback prompt.")
        return "Write a Python function to sort a list."

    with open(file_path, "r", encoding="utf-8") as f:
        return f.read().strip()

def generate_code_from_prompt(prompt: str) -> str:
    """Generates code using Gemini based on the provided prompt."""
    directive = (
        "You are a code generation assistant. "
        "When responding, output only the requested code snippet without any additional explanation or commentary."
    )
    full_prompt = f"{directive}\n{prompt}"
    model = genai.GenerativeModel("models/gemini-2.0-flash")
    response = model.generate_content(full_prompt)
    text = response.text.strip()

    # Remove markdown code fences if present
    fence_match = re.search(r"```(?:python)?\n([\s\S]*?)```", text)
    return fence_match.group(1).strip() if fence_match else text

def main():
    """Main function to orchestrate code generation."""
    prompt = read_prompt_from_file("input.txt")
    generated_code = generate_code_from_prompt(prompt)
    #timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = OUTPUT_DIR / "generated.py"
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(generated_code)

    with open("buggy_code.py", "w", encoding="utf-8") as f_main:
            f_main.write(generated_code)

    print(f"âœ… Code generated and saved to {output_file}")
    print("Code also saved as buggy_code in main")

if __name__ == "__main__":
    main()

```

```python
import argparse
import os
import datetime
import requests

# Load API key from environment variable
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
if not GROQ_API_KEY:
    log_message("Error: GROQ_API_KEY environment variable is not set.")
    exit(1)

# Groq model and endpoint
MODEL = "deepseek-r1-distill-llama-70b"  # Corrected to a real model variant
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"
HEADERS = {
    "Authorization": f"Bearer {GROQ_API_KEY}",
    "Content-Type": "application/json",
}

def log_message(message: str):
    """Logs a message with timestamp to log file and prints it.

    Args:
        message (str): The message to log.
    """
    log_folder = os.path.join(os.getcwd(), "logs")
    os.makedirs(log_folder, exist_ok=True)
    log_file = os.path.join(log_folder, "review_log.txt")
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    with open(log_file, "a", encoding="utf-8") as log:
        log.write(f"[{timestamp}] {message}\n")
    print(f"[{timestamp}] {message}")

def read_code_from_file(file_path: str) -> str | None:
    """Reads and returns the code content from the specified file.

    Args:
        file_path (str): Path to the code file.

    Returns:
        str | None: Code content if successful, None otherwise.
    """
    try:
        with open(file_path, "r", encoding="utf-8") as file:
            code = file.read()
        log_message(f"Successfully read code from: {file_path}")
        return code if code.strip() else None
    except Exception as e:
        log_message(f"Failed to read file: {e}")
        return None

def review_code(code_content: str) -> str:
    """Sends code to Groq API and returns the code review report.

    Args:
        code_content (str): The code to be reviewed.

    Returns:
        str: The code review report.
    """
    system_prompt = (
        "You are an expert code reviewer. Carefully check for linting errors, boundary conditions, "
        "runtime risks, and missing try-except blocks. Generate a verbose report with feedback on code quality, "
        "robustness, and specific problematic areas. "
        "Start with 'Code Review Report by supergit_reviewer:' and end with 'End of Review Report'."
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"Please review the following code:\n\n```python\n{code_content}\n```"}
    ]

    payload = {"model": MODEL, "messages": messages}
    try:
        response = requests.post(GROQ_API_URL, headers=HEADERS, json=payload)
        response.raise_for_status()
        content = response.json()["choices"][0]["message"]["content"]
        log_message("Review received successfully.")
        return content
    except Exception as e:
        log_message(f"Failed to get review: {e}")
        return "Error in code review process."

def save_review(review_text: str, original_file: str):
    """Saves the review report to a file in the reviews folder.

    Args:
        review_text (str): The review text to save.
        original_file (str): The original file name that was reviewed.
    """
    reviews_folder = os.path.join(os.getcwd(), "reviews")
    os.makedirs(reviews_folder, exist_ok=True)
    name_without_ext = os.path.splitext(os.path.basename(original_file))[0]
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    review_file_path = os.path.join(reviews_folder, f"{name_without_ext}_review_{timestamp}.txt")

    try:
        with open(review_file_path, "w", encoding="utf-8") as f:
            f.write(review_text)
        log_message(f"Review saved to: {review_file_path}")
    except Exception as e:
        log_message(f"Failed to save review: {e}")



def main():
    """Main function to parse arguments and run the code review."""
    parser = argparse.ArgumentParser(description="Review Python code using Groq.")
    parser.add_argument("--file", required=True, help="Path to the Python file to review.")
    args = parser.parse_args()

    code_content = read_code_from_file(args.file)
    if code_content:
        review = review_code(code_content)
        save_review(review, args.file)


if __name__ == "__main__":
    main()

```

```python
import os
import requests
import re
import shutil


GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
MODEL = "llama-3.3-70b-versatile"
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"


HEADERS = {
    "Authorization": f"Bearer {GROQ_API_KEY}",
    "Content-Type": "application/json",
    #"HTTP-Referer": "http://localhost",  # Replace with your project site or GitHub if deploying
    "X-Title": "Code Review CLI Tool"
}

OUTPUT_DIR = "output"
os.makedirs(OUTPUT_DIR, exist_ok=True)

def extract_code_and_review(response_text: str) -> tuple[str, str]:
    """Extracts code and review from the LLM response.

    Args:
        response_text (str): The full text response from the LLM.

    Returns:
        tuple[str, str]: A tuple containing the extracted code and the explanation/review.
    """
    # Extract code block if present
    code_blocks = re.findall(r"```(?:python)?\s*(.*?)```", response_text, re.DOTALL)
    
    if code_blocks:
        code = code_blocks[0].strip()
        explanation = response_text.replace(code, "").replace("```", "").strip()
    else:
        lines = response_text.strip().splitlines()
        code_start = 0
        for i, line in enumerate(lines):
            if line.strip().startswith("def ") or line.strip().startswith("class "):
                code_start = i
                break
        explanation = "\n".join(lines[:code_start]).strip()
        code = "\n".join(lines[code_start:]).strip()

    return code, explanation

def review_code(code_text: str) -> str:
    """Sends code to Groq API for review and returns the response.

    Args:
        code_text (str): The code to review.

    Returns:
        str: The Groq API response containing reviewed code and explanations.
    """
    prompt = (
        "You are a helpful code assistant. Please review the following Python code, "
        "explain the issues if any, and then output the corrected version.\n\n"
        f"```python\n{code_text}\n```"
    )
    
    payload = {
        "model": MODEL,
        "messages": [
            {"role": "user", "content": prompt}
        ]
    }

    response = requests.post(GROQ_API_URL, headers=HEADERS, json=payload)
    response.raise_for_status()

    content = response.json()["choices"][0]["message"]["content"]
    return content

def process_code(file_path: str):
    """Reads, reviews, and saves the optimized code.

    Args:
        file_path (str): Path to the code file to be processed.
    """
    with open(file_path, "r", encoding="utf-8") as f:
        code = f.read()

    print("[*] Reviewing code...")

    try:
        response_text = review_code(code)
        code_only, explanation = extract_code_and_review(response_text)

        with open(os.path.join(OUTPUT_DIR, "fixed_code.py"), "w", encoding="utf-8") as f_code:
            f_code.write(code_only)

        with open(os.path.join(OUTPUT_DIR, "review.txt"), "w", encoding="utf-8") as f_review:
            f_review.write(explanation)

        # âœ… Also write to reviewed_code.py at root level
        with open("reviewed_code.py", "w", encoding="utf-8") as f_main:
            f_main.write(code_only)

        print("[âœ“] Code reviewed and saved to:")
        print("   â†’ output/fixed_code.py")
        print("   â†’ reviewed_code.py")
        print("   â†’ output/review.txt")

    except Exception as e:
        print("[!] Error reviewing code:", e)

if __name__ == "__main__":
    file_to_review = "buggy_code.py"  # Replace with your actual file
    process_code(file_to_review)

```

```python
import requests
import os
import logging
import subprocess
import textwrap
from datetime import datetime

# â”€â”€â”€â”€â”€â”€ Logging Configuration â”€â”€â”€â”€â”€â”€
log_file = "test_generation.log"
logging.basicConfig(
    filename=log_file,
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
logging.info("ğŸ”§ Starting test generation process")

# â”€â”€â”€â”€â”€â”€ Load Groq API Key â”€â”€â”€â”€â”€â”€
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

if not GROQ_API_KEY:
    try:
        from dotenv import load_dotenv
        load_dotenv()
        GROQ_API_KEY = os.getenv("GROQ_API_KEY")
    except ModuleNotFoundError:
        logging.error("Missing dotenv module. Set GROQ_API_KEY manually.")
        print("âŒ Missing API key. Set GROQ_API_KEY as an environment variable.")
        exit(1)

# â”€â”€â”€â”€â”€â”€ API Config â”€â”€â”€â”€â”€â”€
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"
MODEL = "llama-3.3-70b-versatile"  

# â”€â”€â”€â”€â”€â”€ Read Reviewed Code â”€â”€â”€â”€â”€â”€
try:
    with open("reviewed_code.py", "r") as file:
        reviewed_code = file.read()
        logging.info("âœ… Successfully read reviewed_code.py")
except FileNotFoundError:
    logging.error("âŒ reviewed_code.py not found.")
    print("âŒ reviewed_code.py not found.")
    exit(1)

# â”€â”€â”€â”€â”€â”€ Prompt â”€â”€â”€â”€â”€â”€
prompt = f"""
You are a **Test Case Generator** for given Python code.  
Your goal is to produce a suite of pytest tests that thoroughly validate the given code.
Generate unit tests using pytest for the following Python code:

{reviewed_code}

Requirements:
- Test both valid and invalid inputs.
- Include edge cases, such as None, negative values, empty strings, zero, large values, etc.
- Validate incorrect behavior: tests MUST fail if the logic in reviewed_code.py is wrong.
- Use meaningful assertions that will fail if code is incorrect.
- Import using 'from reviewed_code import <function>'.
- Only output raw test code. No explanations. No markdown. Just test code.

These tests should enforce correctness, not just check if the function runs.
"""


# â”€â”€â”€â”€â”€â”€ Payload â”€â”€â”€â”€â”€â”€
payload = {
    "model": MODEL,
    "messages": [
        {"role": "system", "content": "You are a helpful AI that writes clean, structured Python unit tests."},
        {"role": "user", "content": prompt