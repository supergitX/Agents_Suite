# ğŸ§¾ Project Overview

This project demonstrates an automated code generation, review, optimization, and testing workflow using Gemini and Groq large language models (LLMs) within a GitHub Actions environment. A user provides a prompt in `input.txt`, which is used to generate Python code. This generated code (`buggy_code.py`) is then automatically reviewed, and the review is used to create an optimized version (`reviewed_code.py`). Finally, tests are generated and run against the reviewed code. The entire process is managed through GitHub Actions workflows.  The project also includes a documentation generation component using Gemini.

# âš™ï¸ Setup & Installation Instructions

1. **Clone the repository:**
   ```bash
   git clone <repository_url>
   ```

2. **Set up a virtual environment:**
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate  # On Linux/macOS
   .venv\Scripts\activate  # On Windows
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up environment variables:**
   Create a `.env` file in the root directory and add the following, replacing placeholders with your actual API keys:

   ```
   GEMINI_API_KEY=<your_gemini_api_key>
   GROQ_API_KEY=<your_groq_api_key>
   ```

# ğŸ§© Explanation of Key Modules, Classes, and Functions

## Python Files

- **`agents/code_generator.py`**: Generates Python code based on a prompt from `input.txt` using Gemini.
- **`agents/reviewer.py`**: Reviews code using the Groq API and saves the review to a file.
- **`agents/optimizer.py`**: Uses the Groq API to provide an optimized version of the code based on the review.
- **`agents/tester.py`**: Generates and runs pytest test cases against the optimized code using the Groq API.
- **`doc-keeper.py`**: Generates documentation for the repository using Gemini.
- **`reviewed_code.py`**: The final, reviewed and optimized version of the generated code. (Generated file)
- **`buggy_code.py`**: The initially generated code from the prompt, intended for review. (Generated file).  This file is a copy of `generated_code/generated.py` to trigger the code review workflow separately.
- **`generated_code/generated.py`**: The initially generated code from `input.txt`. (Generated file)
- **`output/fixed_code.py`**: The reviewed and fixed code by the optimizer agent. (Generated file)
- **`output/review.txt`**: The review generated by the optimizer agent. (Generated file)
- **`test_reviewed_code.py`**: The test cases generated for the reviewed code (Generated file)


## Key Functions (with docstrings):

**`agents/code_generator.py`**:

```python
def read_prompt_from_file(file_path="input.txt") -> str:
    """Reads the plain-text prompt from a .txt file.

    Args:
        file_path (str, optional): Path to the prompt file. Defaults to "input.txt".

    Returns:
        str: The prompt string, or a fallback prompt if the file is not found.
    """
    # ... (Implementation)

def generate_code_from_prompt(prompt: str) -> str:
    """Generates code using Gemini based on the provided prompt.

    Args:
        prompt (str): The prompt string.

    Returns:
        str: The generated code.
    """
    # ... (Implementation)

def main():
    """Main function to orchestrate code generation."""
    # ... (Implementation)
```

**`agents/reviewer.py`**:

```python
def log_message(message: str):
    """Logs a message with timestamp to log file and prints it.

    Args:
        message (str): The message to log.
    """
    # ... (Implementation)

def read_code_from_file(file_path: str) -> str:
    """Reads and returns the code content from the specified file.

    Args:
        file_path (str): The path to the code file.

    Returns:
        str: The code content, or None if the file is not found or empty.
    """
    # ... (Implementation)

def review_code(code_content: str) -> str:
    """Sends code to Groq API and returns the code review report.

    Args:
        code_content (str): The code to review.

    Returns:
        str: The review report.
    """
    # ... (Implementation)

def save_review(review_text: str, original_file: str):
    """Saves the review report to a file in the reviews folder.

    Args:
        review_text (str): The review report text.
        original_file (str): The original code file path.
    """
    # ... (Implementation)
```

**`agents/optimizer.py`**:

```python
def extract_code_and_review(response_text: str) -> tuple[str, str]:
    """Extracts code and review explanation from the Groq API response.

    Args:
        response_text (str): The raw response text.

    Returns:
        tuple[str, str]: The extracted code and the review explanation.
    """
    # ... (Implementation)


def review_code(code_text: str) -> str:
    """Sends code to Groq API for review and returns the response.

    Args:
        code_text (str): The code to review.

    Returns:
        str: The Groq API response.
    """
    # ... (Implementation)

def process_code(file_path: str):
    """Processes the code by reviewing and saving the optimized version.

    Args:
        file_path (str): Path to the code file.
    """
    # ... (Implementation)
```

**`agents/tester.py`**:



```python

def generate_test_cases(code: str, model: str = MODEL) -> str:
    """Generates pytest test cases for the provided code using the specified Groq model.

    Args:
        code (str): The code to be tested.
        model (str, optional): The Groq LLM model to use for test generation. Defaults to MODEL.

    Returns:
        str: The generated test code as a string. Returns an empty string on failure.
    """
    # ... (Implementation - see actual file)
```


**`doc-keeper.py`**:

```python
def read_repo_files(base_path: str) -> dict:
    """Recursively reads all readable files in the repository directory, excluding
    ignored directories and extensions.

    Args:
        base_path (str): The root directory of the repository.

    Returns:
        dict: A dictionary mapping relative file paths to their content.
    """
    # ... (Implementation)


def generate_documentation(repo_files: dict) -> str:
    """Generates Markdown documentation using Gemini based on the provided codebase.

    Args:
        repo_files (dict): A mapping of file paths to file content.

    Returns:
        str: Generated documentation in Markdown format.
    """
    # ... (Implementation)

def write_documentation(doc_text: str, output_file: str = "DOCUMENTATION.md"):
    """Writes the generated documentation to a Markdown file.

    Args:
        doc_text (str): The documentation text.
        output_file (str, optional): The output file name. Defaults to "DOCUMENTATION.md".
    """
    # ... (Implementation)

```


## GitHub Actions Workflows

- **`.github/workflows/generate-code.yml`**: Triggers on changes to `input.txt` and runs `agents/code_generator.py`.
- **`.github/workflows/code-review.yml`**: Triggers after code generation (or directly on push to `buggy_code.py`) and runs `agents/reviewer.py`.
- **`.github/workflows/optimize.yml`**: Triggers after code review and runs `agents/optimizer.py`.
- **`.github/workflows/run-tests.yml`**: Triggers after optimization and runs `agents/tester.py`.
- **`.github/workflows/dockeeper.yml`**: Triggers on pushes to the main branch and runs `doc-keeper.py` to update the documentation.


# ğŸ—‚ Folder & File Structure with Descriptions

```
.
â”œâ”€â”€ agents/                   # Contains the core agent scripts for code generation, review, optimization, and testing.
â”‚   â”œâ”€â”€ code_generator.py
â”‚   â”œâ”€â”€ reviewer.py
â”‚   â”œâ”€â”€ optimizer.py
â”‚   â””â”€â”€ tester.py
â”œâ”€â”€ .github/workflows/        # GitHub Actions workflow files for automating the code lifecycle.
â”‚   â”œâ”€â”€ generate-code.yml
â”‚   â”œâ”€â”€ code-review.yml
â”‚   â”œâ”€â”€ optimize.yml
â”‚   â”œâ”€â”€ run-tests.yml
â”‚   â””â”€â”€ dockeeper.yml
â”œâ”€â”€ generated_code/          # Stores the initially generated code from the prompt.
â”‚   â””â”€â”€ generated.py
â”œâ”€â”€ logs/                    # Contains logs from the review process.
â”‚   â””â”€â”€ review_log.txt      
â”œâ”€â”€ output/                  # Stores the optimized code and review results.
â”‚   â”œâ”€â”€ fixed_code.py
â”‚   â””â”€â”€ review.txt
â”œâ”€â”€ reviews/                 # Stores code review reports.
â”‚   â””â”€â”€ buggy_code_review_*.txt 
â”œâ”€â”€ input.txt                # Input prompt for code generation.
â”œâ”€â”€ buggy_code.py            # Copy of initial generated code, triggers code review workflow.
â”œâ”€â”€ reviewed_code.py         # Optimized code after review.
â”œâ”€â”€ test_reviewed_code.py    # Generated test cases.
â”œâ”€â”€ requirements.txt         # Project dependencies.
â”œâ”€â”€ README.md                # Project description.
â””â”€â”€ DOCUMENTATION.md         # Project documentation (this file).
```

# ğŸ”§ How to Use

1.  **Provide a prompt:**  Write your code generation prompt in `input.txt`.

2.  **Commit and push:** Committing the changes to `input.txt` will trigger the GitHub Actions workflows, automating the code generation, review, optimization, and testing process.

3.  **View Results:**
    *   Generated code: `generated_code/generated.py`, `buggy_code.py`
    *   Reviewed code: `reviewed_code.py`, `output/fixed_code.py`
    *   Review report: `output/review.txt`, `reviews/*.txt`
    *   Test cases: `test_reviewed_code.py`
    *   Documentation: `DOCUMENTATION.md`

# ğŸ¤ Contribution Guidelines

Contributions are welcome!  Please follow these steps:

1.  Fork the repository.
2.  Create a new branch for your feature or bug fix.
3.  Make your changes and commit them.
4.  Push your changes to your fork.
5.  Submit a pull request to the main repository.

# ğŸ§ª Testing & Debugging Instructions

The `test_reviewed_code.py` file contains automatically generated pytest test cases.  You can run these tests locally using:

```bash
pytest test_reviewed_code.py -v  # -v for verbose output
```

The `logs/` directory contains logs from the review process. The `test_generation.log` will give information about the tests and whether they passed or failed.  If tests fail, examine `test_reviewed_code.py` for the specific failures and debug the `reviewed_code.py` accordingly.  Use the review reports in `reviews/` and `output/` to guide debugging.